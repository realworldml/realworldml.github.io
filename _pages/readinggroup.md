---
layout: page
permalink: /readinggroup/
title: Reading Group
description:
nav: true
nav_order: 2
---

<p style="margin-bottom: 3mm">We are holding an online reading group focusing on <strong>modern adaptive experimental design and active learning in the real world</strong>. All interested participants are welcome to join!</p>
<p style="margin-bottom: 3mm">The reading group will be held on <strong>Thursdays</strong> at <strong>10am PST/California</strong>, <strong>6pm GMT/UK</strong>, <strong>7pm CET/Zurich</strong> time. To add this to your calendar, <a href="https://calendar.google.com/calendar/u/0?cid=Mzg1OTc3M2I0MmJjNDIyNGQxZjE2MDA0ZWQ3OGUzNzlhOGViNzdlM2JiMmQ1NmFlYmZkZTU5M2RkOTVhYTEwN0Bncm91cC5jYWxlbmRhci5nb29nbGUuY29t">click here</a>. To receive information via email, <a href="https://forms.gle/Ex1ut4YfL8E3qt7W6">subscribe to our mailing list</a>.</p>
<p style="margin-bottom: 7mm">To join, please use the following <strong>Zoom link:</strong> <a href="https://ethz.zoom.us/j/67585775251">https://ethz.zoom.us/j/67585775251</a> <img src="../assets/img/zoompass.png" alt="" width="25%"></p>

### Speaker Schedule

1. &nbsp;**January 12, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Kelly W. Zhang](https://kellywzhang.github.io/)
    &emsp;&emsp;&emsp;&emsp;<img src="../assets/img/speaker-circles/kelly.png" alt="" width="7%">
2. &nbsp;**January 19, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Kevin Jamieson](https://homes.cs.washington.edu/~jamieson/)
    &emsp;&emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/kevin_j.png" alt="" width="7%">
3. &nbsp;**January 26, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Raul Astudillo](https://raulastudillo.netlify.app/)
    &emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/raul.png" alt="" width="7%">
4. &nbsp;**February 2, 2023** &emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Emmanuel Bengio](https://folinoid.com/)
    &emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/emmanuel.png" alt="" width="7%">
5. &nbsp;**February 16, 2023** &emsp;&nbsp; [Aldo Pacchiano](https://www.aldopacchiano.ai/)
    &emsp;&emsp;&emsp;&ensp;&nbsp;<img src="../assets/img/speaker-circles/aldo.png" alt="" width="7%">
6. &nbsp;**February 23, 2023** &emsp;&nbsp; [Haitham Bou Ammar](http://bouammar.com/)
    &emsp;&nbsp;<img src="../assets/img/speaker-circles/haitham.png" alt="" width="7%">
7. &nbsp;**March 2, 2023** &emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Kevin Tran](https://ktran9891.github.io/)
    &emsp;&emsp;&emsp;&emsp;&emsp;&ensp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/kevin_t.png" alt="" width="7%">
8. &nbsp;**March 9, 2023** &emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Zi Wang](https://ziw.mit.edu/)
    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;&nbsp;<img src="../assets/img/speaker-circles/zi.png" alt="" width="7%">
9. &nbsp;**March 16, 2023** &emsp;&emsp;&nbsp;&nbsp; [Viraj Mehta](https://virajm.com/)
    &emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/viraj.png" alt="" width="7%">
10. &nbsp;**March 23, 2023** &emsp;&emsp;&nbsp;&nbsp; [Johannes Kirschner](https://johannes-kirschner.de/)
    &emsp;&ensp;&nbsp;<img src="../assets/img/speaker-circles/johannes.png" alt="" width="7%">

<div style="margin-bottom: 7mm;"></div>
### Next Talk
<div style="margin-bottom: 5mm;"></div>

<img src="../assets/img/speaker-circles/kevin_t.png" alt="" width="15%"> &emsp;
[Kevin Tran](https://ktran9891.github.io/), &nbsp; **March 2, 2023**

**Title:** Active materials discovery for sustainable energy storage

**Abstract:** We may be able to slow the effects of climate change by transitioning from fossil fuels to solar energy, but solar energy’s inconsistent availability makes implementation difficult. This could be addressed by storing the energy in solar fuels, which are fuels created from solar energy, CO₂, and H₂O. Unfortunately, solar fuels are hindered by insufficiently mature material technologies. In this talk, we discuss two past studies where we used active learning to discover catalysts for solar fuel production. We then review several other examples of active learning in the materials informatics community. We end by discussing open issues with active learning in the materials informatics community.

<!--**Relevant Papers:**-->
<!--- [Paper 1](https://link1)-->
<!--- [Paper 2](https://link2)-->

**Bio:** Kevin Tran is a senior research scientist at Toyota Research Institute (TRI). He works on accelerated materials design and discovery in TRI's Energy & Materials division. His work focuses on developing methods to improve the rate at which we can advance technologies for sustainable energy storage, which often manifests in the form of modeling and automated decision making. Kevin also has experience in software development, process engineering, and biomedical engineering. He received his PhD in chemical engineering at Carnegie Mellon University with Zachary Ulissi, and his bachelor's in chemical engineering at the University of Delaware with Babatunde Ogunnaike.

<div style="margin-bottom: 7mm;"></div>
### Past Talks
<div style="margin-bottom: 5mm;"></div>

<img src="../assets/img/speaker-circles/haitham.png" alt="" width="15%"> &emsp;
[Haitham Bou Ammar](http://bouammar.com/), &nbsp; **February 23, 2023**

**Title:** Combinatorial Bayesian Optimisation with Applications to Antibody discovery and Logic Synthesis EDA

**Abstract:** Many critical emerging real-world problems are instances of combinatorial optimisation with an expensive-to-evaluate (non-linear) black-box objective. Examples are widespread, including machine learning, robotics, medicine and chip design scenarios. In those cases, standard combinatorial solvers, e.g., simulated annealing and genetic algorithms, face difficulties due to the high-sample complexity associated with their heuristics. In this talk, we will elaborate on new combinatorial solvers that extend Bayesian optimisation to discrete spaces and can handle expensive-to-evaluate (non-linear) black-box objectives. We detail Gaussian process kernels that operate in combinatorial spaces and illustrate effective acquisition optimisation techniques over discrete domains. We then apply such solutions to two real-world use cases from antibody design and logic synthesis EDA. Our results demonstrate effective solutions leading us to rank 1 in the EPFL logic synthesis benchmark in 2022.

**Relevant Papers:**
- [Toward real-world automated antibody design with combinatorial Bayesian optimization](https://www.cell.com/cell-reports-methods/pdf/S2667-2375(22)00276-4.pdf)
- [BOiLS: Bayesian Optimisation for Logic Synthesis](https://arxiv.org/abs/2111.06178)

**Bio:** Haitham Bou-Ammar leads the reinforcement learning team at Huawei technologies Research and Development UK and is an Honorary Lecturer at UCL. His primary research interests lie in the field of statistical machine learning and artificial intelligence, focusing on Bayesian optimisation, probabilistic modeling, and reinforcement learning. He is also interested in learning using massive amounts of data over extended time horizons – a property common to "Big-Data" problems. His research also spans different areas of control theory, nonlinear dynamical systems, social networks, and distributed optimisation.

<img src="../assets/img/speaker-circles/aldo.png" alt="" width="15%"> &emsp;
[Aldo Pacchiano](https://www.aldopacchiano.ai/), &nbsp; **February 16, 2023**

**Title:** RLHF: Reinforcement Learning with Once-per-Episode Feedback

**Abstract:** Despite Reinforcement learning's remarkable success in several application and simulation domains, research in the field has barely ventured beyond the typical modeling assumptions underlying the MDP formalism. In this work we aim to reimagine the way in which rewards are produced by moving away from the typical setting of per-step Markovian rewards to a model that instead produces a binary score acting at the trajectory level. While this is an extreme test case for theory, it is also arguably more representative of real-world applications than the traditional requirement in RL practice that the learner receive feedback at every time step. Indeed, in many real-world applications of reinforcement learning, such as self-driving cars, and robotics, it is easier for a human labeler to evaluate whether a learner's complete trajectory was either "good" or "bad," but harder to provide a reward signal at each step. To show that learning is possible in this more challenging setting, we study the case where trajectory labels are generated by an unknown parametric model and provide a statistically and computationally efficient algorithm that achieves sub-linear regret. We will also comment on how to extend these results to the dueling setting where a human labeler decides which one of two trajectories is better.

**Relevant Papers:**
- [On the Theory of Reinforcement Learning with Once-per-Episode Feedback](https://arxiv.org/abs/2105.14363)
- [Dueling RL: Reinforcement Learning with Trajectory Preferences](https://arxiv.org/abs/2111.04850)

**Bio:** Aldo is a Postdoctoral Researcher at Microsoft Research NYC. He obtained his PhD at UC Berkeley where he was advised by Peter Bartlett and Michael Jordan. His research lies in the areas of Reinforcement Learning, Online Learning, Bandits and Algorithmic Fairness. He is particularly interested in furthering our statistical understanding of learning phenomena in adaptive environments and use these theoretical insights and techniques to design efficient and safe algorithms for scientific, engineering, and large-scale societal applications.

<img src="../assets/img/speaker-circles/emmanuel.png" alt="" width="15%"> &emsp;
[Emmanuel Bengio](https://folinoid.com/), &nbsp; **February 2, 2023**

**Title:** Introduction to GFlowNet

**Abstract:** GFlowNet, short for Generative Flow Network, is a new generative modeling framework which we think is particularly suited for discrete, combinatorial objects. The idea behind GFN is to estimate (graph-theoretic) flows in a directed acyclic network. The network represents all possible ways of constructing an object, and so knowing the flow gives us a policy which we can follow to sequentially construct objects in an energy-based fashion (i.e., objects are drawn proportionally to some quantity, like a reward or unnormalized density). In this talk I’ll present the framework, the intuition behind it, some nice properties it has, some cool things we can do with it and some really cool avenues for future work such as drug discovery.

**Relevant Papers:**
- [Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation](https://arxiv.org/abs/2106.04399)
- [Multi-Objective GFlowNets](https://arxiv.org/abs/2210.12765)
- [Colab Notebook](http://colab.research.google.com/drive/1fUMwgu2OhYpQagpzU5mhe9_Esib3Q2VR)

**Bio:** Emmanuel Bengio is an ML Scientist at Recursion, working on the intersection of GFlowNets and de-novo drug design. He did his PhD under Joelle Pineau and Doina Precup at McGill/Mila, focusing on understanding generalization in deep RL.

<img src="../assets/img/speaker-circles/raul.png" alt="" width="15%"> &emsp;
[Raul Astudillo](https://raulastudillo.netlify.app/), &nbsp; **January 26, 2023**

**Title:** Composite Bayesian Optimization for Efficient and Scalable Adaptive Experimentation


[![IMAGE ALT TEXT](http://img.youtube.com/vi/suyiOz4uPPo/0.jpg)](http://www.youtube.com/watch?v=suyiOz4uPPo "Raul Astudillo")
<!--<a href="http://www.youtube.com/watch?v=suyiOz4uPPo"><img src="http://img.youtube.com/vi/suyiOz4uPPo/0.jpg" alt="Raul Astudillo" width="60%"></a>-->

**Abstract:** Experimentation is ubiquitous in science and a key driver of human progress. Many experimentation tasks can be cast as optimization problems with expensive or time-consuming to evaluate objective functions. Bayesian optimization has emerged as a powerful tool for tackling such problems. However, many experimentation tasks arising in high-stakes applications such as materials design and drug discovery are out of the reach of standard approaches. In this talk, I will describe recent advances that aim to address this challenge. In particular, I will focus on how the composite structure of many experimentation tasks can be exploited to improve the efficiency and scalability of Bayesian optimization methods. Finally, I will provide directions for future research toward a general framework for efficient end-to-end adaptive experimental design in complex settings.

**Relevant Papers:**
- [Bayesian Optimization of Function Networks](https://arxiv.org/abs/2112.15311)
- [Thinking inside the box: A tutorial on grey-box Bayesian optimization](https://arxiv.org/abs/2201.00272)
- [Preference Exploration for Efficient Bayesian Optimization with Multiple Outcomes](https://arxiv.org/abs/2203.11382)

**Bio:** Raul is a Postdoctoral Scholar in the Department of Computing and Mathematical Sciences at Caltech, hosted by Professor Yisong Yue. He obtained his Ph.D. in Operations Research and Information Engineering from Cornell University, working under the supervision of Professor Peter Frazier. Before that, he completed the undergraduate program in Mathematics offered jointly by the University of Guanajuato and the Center for Research in Mathematics in Mexico. In 2021, he was a Visiting Researcher at Meta within the Adaptive Experimentation team led by Eytan Bakshy. Raul's research interests lie at the intersection between operations research and machine learning, with an emphasis on Bayesian methods for efficient sequential data collection. His work combines principled decision-theoretic foundations with sophisticated machine learning tools to develop frameworks for adaptive experimentation in robotics, materials design, cellular agriculture, and other scientific applications.

<div style="margin-bottom: 10mm;"></div>

<img src="../assets/img/speaker-circles/kevin_j.png" alt="" width="15%"> &emsp;
[Kevin Jamieson](https://homes.cs.washington.edu/~jamieson/), &nbsp; **January 19, 2023**

**Title:** Lessons learned in deploying bandit algorithms

[![IMAGE ALT TEXT](http://img.youtube.com/vi/RM4oIVd85Nk/0.jpg)](http://www.youtube.com/watch?v=RM4oIVd85Nk "Kevin Jamieson")

**Abstract:** Bandit algorithms, and adaptive experimentation more generally, promise the same statistically significant guarantees as, say, non-adaptive A/B testing, but require far fewer trials which results in a savings in time and money. However, such promises hold only under assumptions that rarely hold in practice, and for algorithms that may require unrealistic data interaction patterns. This talk explores this tension through two case studies in deploying state of the art algorithms to a large online experimentation platform and a robotics application in an industrial setting. Problems will be discussed, sensible solutions will be proposed, and opinions will be offered.

**Relevant Papers:**
- [Instance-optimal PAC Algorithms for Contextual Bandits](https://arxiv.org/abs/2207.02357)
- [A Bandit Approach to Multiple Testing with False Discovery Control](https://arxiv.org/abs/1809.02235)

**Bio:** Kevin Jamieson is an Assistant Professor in the <a href="http://cs.washington.edu/">Paul G. Allen School of Computer Science & Engineering</a> at the University of Washington and is the Guestrin Endowed Professor in Artificial Intelligence and Machine Learning. He received his B.S. from the University of Washington, his M.S. from Columbia University, and his Ph.D. In 2015 from the University of Wisconsin - Madison under the advisement of <a href="http://nowak.ece.wisc.edu/">Robert Nowak</a>, all in electrical engineering. He returned to the University of Washington as faculty in 2017 after a postdoc in the <a href="https://amplab.cs.berkeley.edu/">AMP lab</a> at the University of California, Berkeley working with <a href="https://people.eecs.berkeley.edu/~brecht/">Benjamin Recht</a>. Jamieson's work has been recognized by an NSF CAREER award and Amazon Faculty Research award. Jamieson’s research explores how to leverage already-collected data to inform what future measurements to make next, in a closed loop.

<div style="margin-bottom: 10mm;"></div>

<img src="../assets/img/speaker-circles/kelly.png" alt="" width="15%"> &emsp;
[Kelly W. Zhang](https://kellywzhang.github.io/), &nbsp; **January 12, 2023**

**Title:** Inference after Adaptive Sampling for Longitudinal Data

[![IMAGE ALT TEXT](http://img.youtube.com/vi/o3Hw6BCySXY/0.jpg)](http://www.youtube.com/watch?v=o3Hw6BCySXY "Kelly W. Zhang")

**Abstract:** Online algorithms that learn to optimize treatments over time are increasingly used in a variety of digital intervention problems. These algorithms repeatedly update parameter estimates as data accrues; these parameter estimates are used to inform treatment decisions. These algorithms are called “adaptive sampling” algorithms and the resulting data is considered “adaptively collected.” In this work, we focus on data collected by a large class of adaptive sampling algorithms that are designed to optimize treatment decisions online using accruing data from multiple users. Combining or “pooling” data across users allows adaptive sampling algorithms to potentially learn faster. However, by pooling, these algorithms induce dependence between the collected user data trajectories; this makes statistical inference on this data-type especially challenging. We provide methods to perform a variety of statistical analyses on such adaptively collected data, including Z-estimation, off-policy analyses, and inferring excursion effects. This work is motivated by our work in designing experiments in which online reinforcement learning algorithms pool data across users to learn to optimize treatment decisions, yet reliable statistical inference is essential for conducting a variety of statistical analyses after the experiment is over.

**Bio:** Kelly W. Zhang is a final-year Ph.D. candidate in computer science at Harvard University advised by Susan Murphy and Lucas Janson. Her research focuses on addressing challenges faced when applying reinforcement learning algorithms to real-world problems. She has developed methods for statistical inference for data collected by bandit and reinforcement learning algorithms, i.e., adaptively collected data. She also works on developing the reinforcement learning algorithm to be used in Oralytics, a mobile health app aimed to help users develop healthy oral hygiene habits, in collaboration with Oral-B and researchers at UCLA and UMichigan. She is supported by an NSF Graduate Research Fellowship.



<!--1. &nbsp;**January 12, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Kelly W. Zhang](https://kellywzhang.github.io/), Harvard University-->
<!--    &emsp;&emsp;&emsp;&emsp;<img src="../assets/img/speaker-circles/kelly.png" alt="" width="5%">-->
<!--2. &nbsp;**January 19, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Kevin Jamieson](https://homes.cs.washington.edu/~jamieson/), University of Washington-->
<!--    &emsp;&emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/kevin_j.png" alt="" width="5%">-->
<!--3. &nbsp;**January 26, 2023** &emsp;&nbsp;&nbsp;&nbsp; [Raul Astudillo](https://raulastudillo.netlify.app/), Caltech-->
<!--    &emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/raul.png" alt="" width="5%">-->
<!--4. &nbsp;**February 2, 2023** &emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Emmanuel Bengio](https://folinoid.com/), Recursion-->
<!--    &emsp;&emsp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/emmanuel.png" alt="" width="5%">-->
<!--5. &nbsp;**February 9, 2023** &emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Zi Wang](https://ziw.mit.edu/), Google Brain-->
<!--    &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;&nbsp;<img src="../assets/img/speaker-circles/zi.png" alt="" width="5%">-->
<!--6. &nbsp;**February 16, 2023** &emsp;&nbsp; [Johannes Kirschner](https://johannes-kirschner.de/), University of Alberta-->
<!--    &emsp;&ensp;&nbsp;<img src="../assets/img/speaker-circles/johannes.png" alt="" width="5%">-->
<!--7. &nbsp;**February 23, 2023** &emsp;&nbsp; [Haitham Bou Ammar](http://bouammar.com/), UCL and Huawei London-->
<!--    &emsp;&nbsp;<img src="../assets/img/speaker-circles/haitham.png" alt="" width="5%">-->
<!--8. &nbsp;**March 2, 2023** &emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp; [Kevin Tran](https://ktran9891.github.io/), Toyota Research Institute-->
<!--    &emsp;&emsp;&emsp;&emsp;&emsp;&ensp;&nbsp;&nbsp;<img src="../assets/img/speaker-circles/kevin_t.png" alt="" width="5%">-->

<!--<br/>-->
<!--<img src="../assets/img/speaker-circles/kelly.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/kevin_j.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/raul.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/emmanuel.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/zi.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/johannes.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/haitham.png" alt="" width="10%"> &nbsp;-->
<!--<img src="../assets/img/speaker-circles/kevin_t.png" alt="" width="10%"> &nbsp;-->
